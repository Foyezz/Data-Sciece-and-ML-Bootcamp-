{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb4686e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "id": "4ad9e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "id": "8e7786a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970a164",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "id": "1a877103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'Data/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'Data/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'Data/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'Data/digit_ytest.csv'\n",
    "\n",
    "LOGGING_PATH = 'tesorboard_mnist_digit_logs/'\n",
    "\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba88f4",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "id": "d93fbfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter = ',', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "id": "aeb68895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 1419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "id": "b6bad876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 1420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter= ',', dtype = int)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "id": "764f2440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.3 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter = ',', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "id": "62f8af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.78 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter = ',', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "id": "b3e108bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_all.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5f7d4",
   "metadata": {},
   "source": [
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "id": "943fbdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 1424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "id": "d66a4d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 1425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "id": "7a9408b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 1426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 means complete white and 255 means complete black\n",
    "x_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "id": "26aa20e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 1427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "id": "aa5d8ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 1428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_all[0] \n",
    "y_train_all[:5]  # shows the output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e907ee9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "id": "a2a18817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scale the features\n",
    "x_train_all, x_test = x_train_all/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "id": "e64d91a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 1430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "id": "93e98d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 1431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde288a",
   "metadata": {},
   "source": [
    "### Convert target value to one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "id": "07f77bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "id": "25c5f480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all[:9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1434,
   "id": "20a2d035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 1434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "id": "49c7562f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 1435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.eye(NR_CLASSES)[y_test]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca65177",
   "metadata": {},
   "source": [
    "### Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "id": "c04e9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "id": "6abdd9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000, 10)\n",
      "(50000, 784) (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1158bb",
   "metadata": {},
   "source": [
    "# Setup Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "id": "c19dc8ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # number of sample will be decided later(None = ?)\n",
    "X = tf.compat.v1.placeholder(tf.float32, shape = [None, TOTAL_INPUTS], name = 'X') \n",
    "Y = tf.compat.v1.placeholder(tf.float32, shape = [None, NR_CLASSES], name = 'Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117a144",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986547e8",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "id": "57eb9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2e7e7",
   "metadata": {},
   "source": [
    "### Layer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "83266f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_layer(input, weight_dim, bias_dim, name):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        # setting up of weights\n",
    "        initial_w = tf.random.truncated_normal(shape = weight_dim, stddev= 0.1, seed = 42)\n",
    "        w = tf.Variable(initial_value = initial_w, name = 'W') \n",
    "\n",
    "        # setting up of biases\n",
    "        initial_b = tf.constant(value = 0.0, shape = bias_dim)\n",
    "        b = tf.Variable(initial_value = initial_b, name = 'B')\n",
    "\n",
    "        # output of Output layer\n",
    "        layer_in = tf.matmul(input, w) + b\n",
    "        \n",
    "        if name == 'out':\n",
    "            layer_out = tf.nn.softmax(layer_in)\n",
    "        else:\n",
    "            layer_out = tf.nn.relu(layer_in)\n",
    "        \n",
    "        tf.compat.v1.summary.histogram('weights', w)\n",
    "        tf.compat.v1.summary.histogram('biases', b)\n",
    "        \n",
    "        return layer_out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "id": "f4817e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model without drop out\n",
    "# layer_1 = setup_layer(X, weight_dim = [TOTAL_INPUTS, n_hidden1], bias_dim = [n_hidden1], name = 'layer_1')\n",
    "# layer_2 = setup_layer(layer_1, weight_dim = [n_hidden1, n_hidden2], bias_dim = [n_hidden2], name = 'layer_2')\n",
    "# output = setup_layer(layer_2, weight_dim = [n_hidden2, NR_CLASSES], bias_dim = [NR_CLASSES], name = 'out')\n",
    "\n",
    "\n",
    "# model_name = f'{n_hidden1}-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "c393522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\foyez\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = setup_layer(X, weight_dim = [TOTAL_INPUTS, n_hidden1], bias_dim = [n_hidden1], name = 'layer_1')\n",
    "\n",
    "# dropout layer\n",
    "layer_drop = tf.compat.v1.nn.dropout(layer_1, keep_prob= 0.8, name= 'dropout_layer')\n",
    "\n",
    "layer_2 = setup_layer(layer_drop, weight_dim = [n_hidden1, n_hidden2], bias_dim = [n_hidden2], name = 'layer_2')\n",
    "output = setup_layer(layer_2, weight_dim = [n_hidden2, NR_CLASSES], bias_dim = [NR_CLASSES], name = 'out')\n",
    "\n",
    "\n",
    "model_name = f'{n_hidden1}-DO-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b3cc7",
   "metadata": {},
   "source": [
    "# Tensorboard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "id": "270812ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created directories!\n"
     ]
    }
   ],
   "source": [
    "# Folder for tensorboard\n",
    "folder_name = f'{model_name} at {strftime(\"%H-%M\")}'\n",
    "\n",
    "directory = os.path.join(LOGGING_PATH, folder_name)\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(directory)\n",
    "except OSError as exception:\n",
    "    print(exception.strerror)\n",
    "    \n",
    "else:\n",
    "    print('Successfully created directories!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee6129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca0a8e09",
   "metadata": {},
   "source": [
    "# Loss, Optimisation & Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d3ee2e",
   "metadata": {},
   "source": [
    "### Defining the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "id": "1194f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss_calc'):\n",
    "    #function to compute the average softmax cross-entropy loss between the predicted output and the true label\n",
    "    loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(labels= Y, logits=output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff1157",
   "metadata": {},
   "source": [
    "### Defining the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "id": "f094fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    # declare the optimizer and step\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17a40f",
   "metadata": {},
   "source": [
    "### Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "id": "651865db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy_calc'):\n",
    "    correct_pred = tf.equal(tf.math.argmax(output, axis= 1), tf.math.argmax(Y, axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "id": "935703f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('performance'):\n",
    "\n",
    "    tf.compat.v1.summary.scalar('accuarcy', accuracy)\n",
    "\n",
    "    #add summary for the loss\n",
    "    tf.compat.v1.summary.scalar('cost', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ff96a",
   "metadata": {},
   "source": [
    "### Check Input Images in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "id": "c8abc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope('show_image'):\n",
    "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    tf.compat.v1.summary.image('image_input', x_image, max_outputs= 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a82d7d",
   "metadata": {},
   "source": [
    "# Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "id": "826c6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beabc31",
   "metadata": {},
   "source": [
    "### Setup Filewriter & Merge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "e566b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.compat.v1.summary.merge_all()\n",
    "\n",
    "train_writer = tf.compat.v1.summary.FileWriter(directory + '/train')\n",
    "train_writer.add_graph(sess.graph)\n",
    "\n",
    "validation_writer = tf.compat.v1.summary.FileWriter(directory + '/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "id": "d396d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Merge/MergeSummary:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(merged_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7eb95b",
   "metadata": {},
   "source": [
    "### Initialise all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "id": "8f6199cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6906d3b4",
   "metadata": {},
   "source": [
    "### Batching the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "id": "488ea4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 1000\n",
    "num_examples = y_train.shape[0]\n",
    "nr_iterations = int(num_examples / size_of_batch)\n",
    "\n",
    "index_in_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "id": "ee1af64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 1501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "id": "2f52970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch = index_in_epoch + batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return data[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba0ecf",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a339a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "id": "18b616e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t| Training Accuracy = 0.8410000205039978\n",
      "Epoch 1 \t| Training Accuracy = 0.859000027179718\n",
      "Epoch 2 \t| Training Accuracy = 0.8640000224113464\n",
      "Epoch 3 \t| Training Accuracy = 0.871999979019165\n",
      "Epoch 4 \t| Training Accuracy = 0.9490000009536743\n",
      "Epoch 5 \t| Training Accuracy = 0.9769999980926514\n",
      "Epoch 6 \t| Training Accuracy = 0.9769999980926514\n",
      "Epoch 7 \t| Training Accuracy = 0.9789999723434448\n",
      "Epoch 8 \t| Training Accuracy = 0.9810000061988831\n",
      "Epoch 9 \t| Training Accuracy = 0.9789999723434448\n",
      "Epoch 10 \t| Training Accuracy = 0.984000027179718\n",
      "Epoch 11 \t| Training Accuracy = 0.9879999756813049\n",
      "Epoch 12 \t| Training Accuracy = 0.9850000143051147\n",
      "Epoch 13 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch 14 \t| Training Accuracy = 0.9860000014305115\n",
      "Epoch 15 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch 16 \t| Training Accuracy = 0.9879999756813049\n",
      "Epoch 17 \t| Training Accuracy = 0.9900000095367432\n",
      "Epoch 18 \t| Training Accuracy = 0.9900000095367432\n",
      "Epoch 19 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 20 \t| Training Accuracy = 0.9879999756813049\n",
      "Epoch 21 \t| Training Accuracy = 0.9879999756813049\n",
      "Epoch 22 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 23 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 24 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 25 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 26 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 27 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 28 \t| Training Accuracy = 0.9900000095367432\n",
      "Epoch 29 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 30 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 31 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 32 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 33 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 34 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 35 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 36 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 37 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 38 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 39 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 40 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 41 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 42 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 43 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 44 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 45 \t| Training Accuracy = 0.9900000095367432\n",
      "Epoch 46 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 47 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch 48 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch 49 \t| Training Accuracy = 0.9919999837875366\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nr_epochs):\n",
    "    \n",
    "    # --------------------Traning Dataset-----------------------#\n",
    "    \n",
    "    for i in range(nr_iterations):\n",
    "        batch_x, batch_y = next_batch(batch_size= size_of_batch, data = x_train, labels= y_train)\n",
    "        \n",
    "        feed_dictionary = {X: batch_x, Y: batch_y}\n",
    "        \n",
    "        sess.run(train_step, feed_dict= feed_dictionary)\n",
    "    s, batch_accuracy = sess.run(fetches=[merged_summary, accuracy], feed_dict= feed_dictionary)\n",
    "    \n",
    "    train_writer.add_summary(s, epoch)\n",
    "        \n",
    "    print(f'Epoch {epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
    "    \n",
    "    # ===================Validation==============================\n",
    "    \n",
    "    summary = sess.run(fetches= merged_summary, feed_dict= {X: x_val, Y: y_val})\n",
    "    validation_writer.add_summary(summary, epoch)\n",
    "\n",
    "print('Done Training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b5a06",
   "metadata": {},
   "source": [
    "# Reset for the Next Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "id": "41bb4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "validation_writer.close()\n",
    "sess.close()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dd144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2254def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d160d48d",
   "metadata": {},
   "source": [
    "# Code for 1st Part of the Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6465a1d",
   "metadata": {},
   "source": [
    "1st Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "id": "a2746ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with tf.name_scope('First_Hidden_Layer'):\n",
    "\n",
    "#     # setting up weights\n",
    "#     initial_w1 = tf.random.truncated_normal(shape = [TOTAL_INPUTS, n_hidden1], stddev= 0.1, seed = 42)\n",
    "\n",
    "#     # create the weights of neurons\n",
    "#     w1 = tf.Variable(initial_value = initial_w1, name = 'w1')\n",
    "\n",
    "#     # create the biases \n",
    "#     initial_b1 = tf.constant(value = 0.0, shape = [n_hidden1])\n",
    "#     b1 = tf.Variable(initial_value = initial_b1, name = 'b1')\n",
    "\n",
    "#     # calculation of 1st layer input\n",
    "#     layer1_in = tf.matmul(X, w1) + b1\n",
    "\n",
    "#     # defining the activation function and layer1 output\n",
    "#     layer1_out = tf.nn.relu(layer1_in)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e2695",
   "metadata": {},
   "source": [
    "2nd Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "id": "23c60e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with tf.name_scope('Second_Hidden_Layer'):\n",
    "\n",
    "#     # setting up of weights\n",
    "#     initial_w2 = tf.random.truncated_normal(shape = [n_hidden1, n_hidden2], stddev= 0.1, seed = 42)\n",
    "#     w2 = tf.Variable(initial_value = initial_w2, name = 'w2') \n",
    "\n",
    "#     # setting up of biases\n",
    "#     initial_b2 = tf.constant(value = 0.0, shape = [n_hidden2])\n",
    "#     b2 = tf.Variable(initial_value = initial_b2, name = 'b2')\n",
    "\n",
    "#     # calculation of 2nd layer input\n",
    "#     layer2_in = tf.matmul(layer1_out, w2) + b2\n",
    "\n",
    "#     # defining the activation function and layer2 output\n",
    "#     layer2_out = tf.nn.relu(layer2_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93837e02",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "id": "723f48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with tf.name_scope('output_layer'):\n",
    "\n",
    "#     # setting up of weights\n",
    "#     initial_w3 = tf.random.truncated_normal(shape = [n_hidden2, NR_CLASSES], stddev= 0.1, seed = 42)\n",
    "#     w3 = tf.Variable(initial_value = initial_w3, name = 'w3') \n",
    "\n",
    "#     # setting up of biases\n",
    "#     initial_b3 = tf.constant(value = 0.0, shape = [NR_CLASSES])\n",
    "#     b3 = tf.Variable(initial_value = initial_b3, name = 'b3')\n",
    "\n",
    "#     # output of Output layer\n",
    "#     layer3_in = tf.matmul(layer2_out, w3) + b3\n",
    "#     output = tf.nn.softmax(layer3_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "id": "cd0f5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1.eval(sess)  shows all initial weights\n",
    "# b1.eval(sess)  shows all initial biases\n",
    "\n",
    "#b3.eval(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc56662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
